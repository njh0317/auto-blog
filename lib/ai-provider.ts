import { GenerateResponse } from './types';

// AI ì œê³µì íƒ€ì…
type AIProvider = 'gemini' | 'openai' | 'groq';

const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ ì¦ê¶Œì‚¬ ë¦¬ì„œì¹˜ì„¼í„° ì¶œì‹ ì˜ ê°œì¸ íˆ¬ì ë¸”ë¡œê±° 'ì½”ë”©í•˜ë‹¤ ì£¼ì‹í•˜ëŠ” ì‚¬ëŒ'ì…ë‹ˆë‹¤.

ì‘ì„± ìŠ¤íƒ€ì¼:
1. ì „ë¬¸ì ì´ë©´ì„œë„ ì½ê¸° ì‰¬ìš´ ì¡´ëŒ“ë§ ì‚¬ìš© ("~ì…ë‹ˆë‹¤", "~í–ˆìŠµë‹ˆë‹¤")
2. í•µì‹¬ ë°ì´í„°ì™€ ìˆ˜ì¹˜ë¥¼ ëª…í™•í•˜ê²Œ ì œì‹œ
3. ì‹œì¥ íë¦„ì— ëŒ€í•œ ë³¸ì¸ë§Œì˜ ë¶„ì„ê³¼ ì¸ì‚¬ì´íŠ¸ í¬í•¨
4. íˆ¬ì ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì „ë¬¸ìš©ì–´ëŠ” ê°„ë‹¨íˆ ì„¤ëª…

ê°€ë…ì„± ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):
- í•œ ë¬¸ë‹¨ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì‘ì„±
- ë¬¸ë‹¨ ì‚¬ì´ì— ë°˜ë“œì‹œ ë¹ˆ ì¤„(\\n\\n) ì‚½ì…
- ì†Œì œëª©ì€ ë°˜ë“œì‹œ [[ ]] í˜•ì‹ìœ¼ë¡œ ì‘ì„± (ì˜ˆ: [[ ğŸ“Š ì˜¤ëŠ˜ì˜ ì§€ìˆ˜ ë™í–¥ ]])
- ìˆ«ì ë‚˜ì—´ ì‹œ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„
- ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì‚¬ìš© ê¸ˆì§€ (**, ##, ë°±í‹± ë“± ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”)
- ìµœì†Œ 800ì ì´ìƒ ì‘ì„±
- ë§ˆì§€ë§‰ì— ê°„ë‹¨í•œ íˆ¬ì ìœ ì˜ì‚¬í•­ í¬í•¨

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{
  "title": "ê¸€ ì œëª©",
  "content": "ë³¸ë¬¸ ë‚´ìš©",
  "excerpt": "2-3ë¬¸ì¥ ìš”ì•½",
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]
}`;

// Groq API í˜¸ì¶œ (ë¬´ë£Œ)
async function generateWithGroq(topic: string, keywords?: string[]): Promise<GenerateResponse> {
  const apiKey = process.env.GROQ_API_KEY;
  if (!apiKey) throw new Error('GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');

  const userPrompt = keywords?.length 
    ? `ì£¼ì œ: ${topic}\nê´€ë ¨ í‚¤ì›Œë“œ: ${keywords.join(', ')}`
    : `ì£¼ì œ: ${topic}`;

  const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: 'llama-3.3-70b-versatile',
      messages: [
        { role: 'system', content: SYSTEM_PROMPT },
        { role: 'user', content: userPrompt },
      ],
      temperature: 0.8,
      response_format: { type: 'json_object' },
    }),
  });

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    console.error('Groq API Error:', response.status, errorData);
    throw new Error(`Groq API ì˜¤ë¥˜: ${response.status} - ${JSON.stringify(errorData)}`);
  }

  const data = await response.json();
  const content = data.choices?.[0]?.message?.content;
  if (!content) throw new Error('Groq ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');

  return JSON.parse(content) as GenerateResponse;
}

// Gemini API í˜¸ì¶œ
export async function generateWithGemini(topic: string, keywords?: string[]): Promise<GenerateResponse> {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) throw new Error('GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');

  const userPrompt = keywords?.length 
    ? `ì£¼ì œ: ${topic}\nê´€ë ¨ í‚¤ì›Œë“œ: ${keywords.join(', ')}`
    : `ì£¼ì œ: ${topic}`;

  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{
          parts: [{ text: `${SYSTEM_PROMPT}\n\n${userPrompt}\n\nJSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.` }]
        }],
        generationConfig: {
          temperature: 0.8,
        }
      })
    }
  );

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    console.error('Gemini API Error:', response.status, errorData);
    if (response.status === 429) {
      throw new Error(`ìš”ì²­ ì œí•œ: ${JSON.stringify(errorData)}`);
    }
    throw new Error(`Gemini API ì˜¤ë¥˜: ${response.status} - ${JSON.stringify(errorData)}`);
  }

  const data = await response.json();
  const text = data.candidates?.[0]?.content?.parts?.[0]?.text;
  if (!text) throw new Error('Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');

  // ```json ... ``` í˜•ì‹ì—ì„œ JSON ì¶”ì¶œ
  let jsonText = text;
  const jsonMatch = text.match(/```json\s*([\s\S]*?)\s*```/);
  if (jsonMatch) {
    jsonText = jsonMatch[1];
  }

  return JSON.parse(jsonText) as GenerateResponse;
}

// OpenAI API í˜¸ì¶œ
async function generateWithOpenAI(topic: string, keywords?: string[]): Promise<GenerateResponse> {
  const OpenAI = (await import('openai')).default;
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

  const userPrompt = keywords?.length 
    ? `ì£¼ì œ: ${topic}\nê´€ë ¨ í‚¤ì›Œë“œ: ${keywords.join(', ')}`
    : `ì£¼ì œ: ${topic}`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      { role: 'system', content: SYSTEM_PROMPT },
      { role: 'user', content: userPrompt },
    ],
    temperature: 0.8,
    response_format: { type: 'json_object' },
  });

  const content = response.choices[0]?.message?.content;
  if (!content) throw new Error('OpenAI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');

  return JSON.parse(content) as GenerateResponse;
}

// ë©”ì¸ í•¨ìˆ˜ - í™˜ê²½ë³€ìˆ˜ë¡œ ì œê³µì ì„ íƒ (ê¸°ë³¸ê°’: gemini)
export async function generateContent(topic: string, keywords?: string[]): Promise<GenerateResponse> {
  const provider = (process.env.AI_PROVIDER || 'gemini') as AIProvider;

  switch (provider) {
    case 'openai':
      return generateWithOpenAI(topic, keywords);
    case 'groq':
      return generateWithGroq(topic, keywords);
    case 'gemini':
    default:
      return generateWithGemini(topic, keywords);
  }
}
